{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a regulation prior network for netZoo tools\n",
    "Marouen Ben Guebila<sup>1</sup>\n",
    "\n",
    "<sup>1</sup> Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Several Network Zoo [netzoo](netzoo.github.io) tools require a regulation prior network ($W_0$) to use it as an initial estimate and a starting point for the inference of the final network $W$. Regulation prior networks are based on Transcription Factor Binding Sites (TFBS) detected in the promoter regions of target genes.\n",
    "\n",
    "In this tutorial, we will go through the following steps to reconstruct a regulation prior for netzoo tools. \n",
    "\n",
    "- First, we will extract the sequences of the promoter regions of human genes.\n",
    "\n",
    "- Second, we will use a database of TF Position Weight Matrices (PWMs), that associates to each TF a sequence motif where the TF is likely to bind.\n",
    "\n",
    "- Third, we will scan the sequences of the promoters for TFBS using TF PWMs and a scan tool called FIMO<sup>1</sup>.\n",
    "\n",
    "- Finally, we will derive the regulation prior network as a discrete binary network and a continuous network by using several derivations. We are particularly interested in the continuous derivations because [as shown previously](Controlling_The_Variance_Of_PANDA_Networks.ipynb) binary priors induce a strong bias on the final network.\n",
    "\n",
    "Some parts of this notebook are intended for demonstration purposes only, because running the whole pipeline takes about a week on a 36 core machine. The variable `precomputed` was set to 1 to avoid executing the code on the server of the time-consuming part. However, you can try this code on your own cluster by:\n",
    "\n",
    "- Installing the dependencies listed below,\n",
    "\n",
    "- Changing the paths with those of your machine,\n",
    "\n",
    "- Or you can directly use the final computed networks that we provide at the end.\n",
    "\n",
    "## Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO # to run Biopython\n",
    "import pandas as pd\n",
    "import multiprocessing # to run FIMO in parallel\n",
    "from functools import partial\n",
    "from netZooPy.panda.panda import Panda # to build a GRN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the sequences of promoter regions\n",
    "\n",
    "First, you need the sequences of human genes from the latest builld (hg38). The sequences can be downloaded from the UCSC website https://genome.ucsc.edu/cgi-bin/hgGateway. When you download the gene sequences, you have the option to pick the start nucleotide in relation to the Transcription Start Site (TSS) and the end nucleotide relative to the Transcription End Site (TSE). Here, we chose gene sequences that start at TSS-1000 base pairs and end at TSE+1000 basepairs. In total, there are 38723 gene sequences.\n",
    "\n",
    "Since, we are interested in the promoter regions of the gene, we need to reduce the sequence. We are interested in the region that is TSS+/-1kb, therefore we need to take the first 2kb of each sequence using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceSequence(sequence):\n",
    "    seq=sequence[:2000]#since start is tss-1000, then we take the 2000bp upstream \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will convert gene names from ENSG to gene symbols, using this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read conversion file\n",
    "geneCorr = pd.read_csv('/opt/data/netZooPy/regPrior/hg38_Tss_coordinates.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can cut all the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed=1\n",
    "input_file ='/opt/data/netZooPy/regPrior/hg38_sequence_Tss1000_Tse1000.fasta'\n",
    "output_file='/opt/data/netZooPy/regPrior/hg38_sequence_Tss1000_Tss1000.fasta'\n",
    "if precomputed==0:\n",
    "    fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "    finalSeq=''\n",
    "    namelist=[]\n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        new_sequence   = reduceSequence(sequence)\n",
    "        name           = name[16:]\n",
    "        boolInd        = np.in1d(geneCorr.iloc[:,1],name)\n",
    "        name           = geneCorr.iloc[boolInd,12].values[0]\n",
    "        interName      = np.intersect1d(name, namelist)\n",
    "        if interName.size == 0:\n",
    "            namelist.append(name)\n",
    "        else:\n",
    "            continue\n",
    "        name           = '>' + name\n",
    "        print(name)\n",
    "        finalSeq       = finalSeq + name + '\\n' + new_sequence + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the trimmed sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if precomputed==0:\n",
    "    # save file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(finalSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and cleaning position weight matrices (PWMs)\n",
    "The second step is to collect the PWMs for each TF which characterize their DNA binding motifs. The PWMs will allow us afterwards to scan the sequences obtained earlier for TFBS using the FIMO<sup>1</sup> software. \n",
    "\n",
    "We collected PWMs from [the companion website](http://humantfs.ccbr.utoronto.ca/download.php) to Lambert et al.,<sup>2</sup> which correspond to the database [CIS-BP](http://cisbp.ccbr.utoronto.ca/) 1.94d. In total, there are PWMs for 1149 TFs.\n",
    "\n",
    "First, we need to put the PWMs in the format required for the sequence scanning tool FIMO. FIMO requires a `.meme` format for PWMs, therefore we need to convert PWMs from matrices to meme using [matrix2meme](http://meme-suite.org/doc/matrix2meme.html) from the [meme suite](http://meme-suite.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if precomputed==0:\n",
    "    # convert CIS-BP matrices to matrices\n",
    "    for file in os.listdir():\n",
    "        df=pd.read_csv(file,sep='\\t')\n",
    "        df=df.iloc[:,1:]\n",
    "        os.chdir('/opt/data/netZooPy/regPrior/convPWM')\n",
    "        df.to_csv(file, header=False, index=False, sep='\\t')\n",
    "        os.chdir('/data/PWMs')\n",
    "\n",
    "    # call meme suite meme2mat, some files were not analyzed because some nucleotide positions summed to zero\n",
    "    os.chdir('/opt/data/netZooPy/regPrior/convPWM')\n",
    "    finalTfList=[]\n",
    "    for file in os.listdir():\n",
    "        bashCommand = \"meme/libexec/meme-5.0.5/matrix2meme <\" + file + \"> \" + file + \".meme\"\n",
    "        res=os.system(bashCommand)\n",
    "        if res != 0:\n",
    "            print(file)\n",
    "        else:\n",
    "            finalTfList.append(file[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since TFs may have more than one DNA binding motif, we will select the best motif for each TF as specified by Lambert et al.,<sup>2</sup>, by looking for the boolean `true` in the column `Best motif(s)` in the metadata file `Human_TF_MotifList_v_1.01.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if precomputed==0:\n",
    "    # read TF motif table to select best motif per TF\n",
    "    tf     =pd.read_csv(\"/opt/data/netZooPy/regPrior/Human_TF_MotifList_v_1.01.csv\",dtype=str)\n",
    "    indTF  =np.in1d(tf.iloc[:,6],finalTfList)\n",
    "    tff    =tf\n",
    "    tf     =tf.iloc[indTF,:]\n",
    "    initTF =tf.iloc[0,1]\n",
    "    tflist, tfflist =[],[]\n",
    "    tflist.append(tf.iloc[0,6])\n",
    "    tfflist.append(initTF)\n",
    "    tfFound=0\n",
    "    for i in range(tf.shape[0]):\n",
    "        newTF = tf.iloc[i, 1]\n",
    "        if tfFound==1 and initTF==newTF:\n",
    "            continue\n",
    "        else:\n",
    "            if initTF!=newTF:\n",
    "                if initTF != newTF and tfFound==0:\n",
    "                    tflist.append(tf.iloc[i, 6])\n",
    "                    tfflist.append(tf.iloc[i, 1])\n",
    "                tfFound=0\n",
    "                initTF =newTF\n",
    "            if tf.iloc[i,7]==True:\n",
    "                tflist.append(tf.iloc[i,6])\n",
    "                tfflist.append(tf.iloc[i, 1])\n",
    "                tfFound=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put the converted PWMs in a single file to simplify the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if precomputed==0:\n",
    "    # put pwms in the same file\n",
    "    os.chdir('/opt/data/netZooPy/regPrior/convPWM')\n",
    "    finalMeme = 'MEME version 4\\n\\nALPHABET= ACGT\\n\\nstrands: + -\\n\\nBackground letter frequencies (from uniform background):\\nA 0.25000 C 0.25000 G 0.25000 T 0.25000 \\n\\n'\n",
    "    k=0\n",
    "    finalTFName=[]\n",
    "    for i in range(len(tflist)):\n",
    "        try:\n",
    "            file = open(tflist[i] + '.txt.meme', 'r')\n",
    "            k    = k+1\n",
    "            finalTFName.append(tfflist[i])\n",
    "            data = file.read()\n",
    "            finalMeme = finalMeme + data[145:151] + tfflist[i] + data[152:]\n",
    "            file.close()\n",
    "        except:\n",
    "            print(\"TF not found\")\n",
    "\n",
    "    # save file\n",
    "    with open('allTFs.meme', 'w') as file:\n",
    "        file.write(finalMeme)\n",
    "\n",
    "    # save TFs\n",
    "    with open(\"tfNames.txt\", \"w\") as f:\n",
    "        for s in finalTFName:\n",
    "            f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the regulation prior network\n",
    "\n",
    "In this step, we will scan the promoter sequences for TF binding motifs using FIMO. Our final network will determine the interactions between 1149 TFs and 38723 genes. First, we need to extract gene names and the number of TFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfNames=[]\n",
    "with open(\"/opt/data/netZooPy/regPrior/tfNames.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    tfNames.append(str(line.strip()))\n",
    "\n",
    "input_file = '/opt/data/netZooPy/regPrior/hg38_sequence_Tss1000_Tss1000.fasta'\n",
    "geneNames  = []\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        geneNames.append(name)\n",
    "\n",
    "nTFs       = len(tfNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will run `FIMO` on each gene sequence and for each TF. The output of `FIMO` is a p-value that indicates the likelihood of binding of a given TF in the target sequence using the PWMs that were selected as best in the previous step. Since a TF can have several binding sites in the target sequence, the p-values can be sumamrized using [Fisher's method](https://en.wikipedia.org/wiki/Fisher%27s_method), however, in our case, we will pick the lowest p-value for each TF-gene pair.\n",
    "\n",
    "Before writing the parallel loop, let's discuss the output network of this step. \n",
    "\n",
    "Networks can be binary wherein a value of 1 indicates the presence of a motif in the promoter region and 0 the absence  of a TFBS. The binary values are obtained by thresholding the p-value. We can pick a significance threshold on either the p-values or the multiple testing corrected p-values (q-values). Therefore, we get two binary networks: a p-value thresholded network and a q-value threhsolded network.\n",
    "\n",
    "However, we saw [previously](Controlling_The_Variance_Of_PANDA_Networks.ipynb) that seeding network inference with a binary network induces a strong bias on the distribution of the edges. Therefore, we are interested in deriving a continuous $W_0$.\n",
    "\n",
    "To assess the strength of regulation, models of continuous binding have been used on ChIP-seq binding profiles as functions that decrease monotonically with the distance to TSS<sup>3</sup>. Although these models have been used with ChIP-seq binding peaks over large sequence regions (~1MB), in our case we will apply them to PWM hits over smaller sequences (2kb). The difference is that with ChIP-seq data, TF binding has been established however with TF DNA binding motif scans, binding is hypothetical or proven in vitro at best<sup>4</sup>.\n",
    "\n",
    "The following continuous models are structurally simialr with vairations in the parameters.\n",
    "\n",
    "### 1. Garcia-Alonso model\n",
    "This model has been applied on ChIP-seq data<sup>5</sup> to compute the strength of regulation $s$ between a gene $g$ and a TF $t$ using the following equation\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "s(t,g)=\\sum_{k} e^{-d/(md\\times10+1)}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "such as $k$ is the number of binding sites for a given TF in the target sequence, $d$ is the distance between the $k^{th}$ detected motif in the sequence and the TSS, $md$ is the median of all $k$ motifs.\n",
    "\n",
    "Since we are considering a region of TSS+/-1kb, we will consider the motifs occuring after the TSS as having a distance of 0 to the TSS for this model and all the other models. Therefore, we added 1 in the denominator of the exponential to account for cases where the all the motifs are after the TSS.\n",
    "\n",
    "We can get an intuition of the model by running a with two different median values, one with a scaling factor and one without a scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=200\n",
    "x=np.arange(0,1000)\n",
    "plt.plot(np.concatenate([-np.flip(x),x[1:]]), np.concatenate([np.exp(-np.flip(x) / (10*md)), np.ones(999) ]), label=\"md200\" )\n",
    "plt.legend()\n",
    "plt.xlabel('Distance to TSS (bp)')\n",
    "plt.ylabel('Strength of regulation')\n",
    "\n",
    "md=200\n",
    "x=np.arange(0,1000)\n",
    "plt.plot(np.concatenate([-np.flip(x),x[1:]]), np.concatenate([np.exp(-np.flip(x) / (md)), np.ones(999)]), label=\"md200 without factor\" )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a scaling factor of 10 seems to give better results since we're working on short sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ouyang model\n",
    "The previous model is a modification of the Ouyang model<sup>6</sup> which has two main differences:\n",
    "\n",
    "- A scaling parameter that was set in the exponential to 5000bp for all TFs except E2f1 that was set to 500bp. In the  previous model, the parameter was replaced by the median of all binding sites, therfore we will keep this modification for our study.\n",
    "\n",
    "- A multiplicative factor to account for ChIP-seq reads mapped on the binding site. However, in our case, we will replace the ChIP mapped reads factor by $-log_{10}(p-value)$ to integrate the significance of binding into the computed score.\n",
    "\n",
    "Therefore, the final model equation is: \n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "s(t,g)=\\sum_{k} -log_{10}(p-value)\\times e^{-d/(md\\times10+1)}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "To get a sense of this function, we can plot the score for one TF assuming a p-value of $10^{-3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval=0.001\n",
    "md=200\n",
    "x=np.arange(0,1000)\n",
    "plt.plot(np.concatenate([-np.flip(x),x[1:]]), np.concatenate([-np.log10(pval)*np.exp(-np.flip(x) / (10*md)), 3*np.ones(999) ]) )\n",
    "plt.xlabel('Distance to TSS (bp)')\n",
    "plt.ylabel('Strength of regulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RP model\n",
    "\n",
    "The Regulatory Potential (RP) model<sup>7</sup> assumes a decay function as the distance from the TSS increases.\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "s(t,g)=\\sum_{k} e^{(-0.5+4\\times d)}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "with $d$ the distance to TSS divided by 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=200\n",
    "x=np.arange(0,1000)/1000\n",
    "plt.plot(np.concatenate([-np.flip(x),x[1:]]), np.concatenate([np.exp(-(0.5+4*np.flip(x))), np.exp(-0.5)*np.ones(999) ]) )\n",
    "plt.xlabel('Distance to TSS (kb)')\n",
    "plt.ylabel('Strength of regulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RP model was later modified<sup>8</sup> to include a parameter that is calibrated using the study data set.\n",
    "\n",
    "There could be many more derivations of continuous regulation strength using gene expression or the binding affinity of TFs. However, we will compute the three previous metrics for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the motif networks\n",
    "\n",
    "Now, let's define a parallel loop to call FIMO on our sequences and compute two binary network and three continuous networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelFIMO(tfi,geneNames,tfNames,pqval):\n",
    "\tregMatQval = np.zeros((1,len(geneNames)))\n",
    "\tregMatQ    = pd.DataFrame(data=regMatQval, columns=geneNames, index=[tfNames[tfi]])\n",
    "\tprint(tfi)\n",
    "\tif pqval==1:\n",
    "\t\tbashCommand = 'fimo --qv-thresh --thresh 0.05 --verbosity 1 --max-stored-scores 100000000 --oc motifResultsTmp' + str(tfi+1)  + ' --motif ' + tfNames[tfi] \\\n",
    "\t\t+ ' /opt/data/netZooPy/regPrior/allTFs.meme /opt/data/netZooPy/regPrior/hg38_sequence_Tss1000_Tss1000.fasta'\n",
    "\telse:\n",
    "\t\tbashCommand = 'fimo --thresh 1e-3 --no-qvalue --verbosity 1 --max-stored-scores 100000000 --oc motifResultsTmp' + str(tfi+1)  + ' --motif ' + tfNames[tfi] \\\n",
    "\t\t+ ' /opt/data/netZooPy/regPrior/allTFs.meme /opt/data/netZooPy/regPrior/hg38_sequence_Tss1000_Tss1000.fasta'\n",
    "\tres = os.system(bashCommand)\n",
    "\tif res != 0:\n",
    "\t\tprint('could not read fimo')\n",
    "\tos.chdir('/opt/data/netZooPy/regPrior/motifResultsTmp' + str(tfi+1))\n",
    "\ttry:\n",
    "\t\ttf = pd.read_csv('fimo.tsv',sep='\\t', comment='#')\n",
    "\t\ttf.iloc[:,3] = 1000 - tf.iloc[:,3] # center index to get TSS=0\n",
    "\t\tfor geneName in geneNames:\n",
    "\t\t\tjset = np.where(np.in1d(tf.iloc[:,2],geneName))\n",
    "\t\t\tif jset[0].size != 0:\n",
    "\t\t\t\tif pqval in (2, 3, 4):\n",
    "\t\t\t\t\t# for continuous networks assume that position>TSS is equal to TSS\n",
    "\t\t\t\t\tindMil=np.where(tf.start < 0)\n",
    "\t\t\t\t\ttf.iloc[indMil[0],3]=0\n",
    "\t\t\t\tif pqval==1:\n",
    "\t\t\t\t\tregMatQ[geneName].iloc[0] = tf.iloc[jset[0],8].min()\n",
    "\t\t\t\telif pqval==0:\n",
    "\t\t\t\t\tregMatQ[geneName].iloc[0] = tf.iloc[jset[0],7].min()\n",
    "\t\t\t\telif pqval==2:\n",
    "\t\t\t\t\tmd=np.median(tf.iloc[jset[0],3])\n",
    "\t\t\t\t\tregMatQ[geneName].iloc[0] = np.sum(np.exp((-tf.iloc[jset[0],3])/((md*10)+1)))\n",
    "\t\t\t\telif pqval==3:\n",
    "\t\t\t\t\tmd=np.median(tf.iloc[jset[0],3])\n",
    "\t\t\t\t\tif any(np.isposinf(np.log10(tf.iloc[jset[0],7]))):\n",
    "\t\t\t\t\t\tprint('Infinite value')\n",
    "\t\t\t\t\ttmpRes = np.multiply(-np.log10(tf.iloc[jset[0],7]),  np.exp((-tf.iloc[jset[0],3])/((md*10)+1)))\n",
    "\t\t\t\t\tregMatQ[geneName].iloc[0] = np.sum(tmpRes)\n",
    "\t\t\t\telif pqval==4:\n",
    "\t\t\t\t\ttmpRes=np.exp( -0.5+4 * (tf.iloc[jset[0],3]/1000) )\n",
    "\t\t\t\t\tregMatQ[geneName].iloc[0] = np.sum(tmpRes)\n",
    "\texcept:\n",
    "\t\tprint('empty fimo result')\n",
    "\tos.chdir('/opt/data/netZooPy/regPrior/data')\n",
    "\tos.system('rm -rf motifResultsTmp' + str(tfi+1))\n",
    "\treturn regMatQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call the loop in parallel, however, it may take some time to compute, therefore we provide the precomputed results. To avoid memory issues and reduce the computation burden, we took the highest threshold of p-value and q-value to be 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeNetworks=0\n",
    "if computeNetworks==1:\n",
    "    # p-value binary network\n",
    "    pool = multiprocessing.Pool(36)\n",
    "    res  = pool.map(partial(parallelFIMO,tfNames=tfNames,geneNames=geneNames,pqval=0), range(nTFs))\n",
    "    res  = pd.concat(res)\n",
    "    res.to_csv('regMatPval1e3.csv')\n",
    "\n",
    "    # q-value binary network\n",
    "    pool = multiprocessing.Pool(36)\n",
    "    res  = pool.map(partial(parallelFIMO,tfNames=tfNames,geneNames=geneNames,pqval=1), range(nTFs))\n",
    "    res  = pd.concat(res)\n",
    "    res.to_csv('regMatQval1e3.csv')\n",
    "\n",
    "    # Continuous network 1\n",
    "    pool = multiprocessing.Pool(36)\n",
    "    res  = pool.map(partial(parallelFIMO,tfNames=tfNames,geneNames=geneNames,pqval=2), range(nTFs))\n",
    "    res  = pd.concat(res)\n",
    "    res.to_csv('regMatCont1.csv')\n",
    "\n",
    "    # Continuous network 2\n",
    "    pool = multiprocessing.Pool(36)\n",
    "    res  = pool.map(partial(parallelFIMO,tfNames=tfNames,geneNames=geneNames,pqval=3), range(nTFs))\n",
    "    res  = pd.concat(res)\n",
    "    res.to_csv('regMatCont2.csv')\n",
    "\n",
    "    # Continuous network 3\n",
    "    pool = multiprocessing.Pool(36)\n",
    "    res  = pool.map(partial(parallelFIMO,tfNames=tfNames,geneNames=geneNames,pqval=4), range(nTFs))\n",
    "    res  = pd.concat(res)\n",
    "    res.to_csv('regMatCont3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the final network\n",
    "### Binary networks\n",
    "We computed two binary networks: the first one is and FDR-corrected p-value network thresholded at 0.05 and the second is a p-value network thresholded at $1e^{-5}$. In other words, if the significance of binding determined by FIMO scan is less than a certain significance threshold, we will assign a binding event and the edge weight will be set to 1, otherwise the edge will be set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmatqval=pd.read_csv('/opt/data/netZooPy/regPrior/regMatQval005.csv',header=0,index_col=0)\n",
    "tresh=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmatqval[(regmatqval>0) & (regmatqval <= tresh)]=1\n",
    "regmatqval[(regmatqval > tresh) & (regmatqval < 1)] =0\n",
    "plt.hist(regmatqval.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmatpval=pd.read_csv('/opt/data/netZooPy/regPrior/regMatPval1e3.csv',header=0,index_col=0)\n",
    "tresh=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmatpval[(regmatpval>0) & (regmatpval <= tresh)]=1\n",
    "regmatpval[(regmatpval > tresh) & (regmatpval < 1)] =0\n",
    "plt.hist(regmatpval.values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the continuous networks\n",
    "We will first start by exploring the edge distribution that each continuous network has and scale them in order to be able to use them for network reconstruction methods.\n",
    "\n",
    "### 1. Garcia-Alonso model\n",
    "\n",
    "We start by loading the network that we computed to explore basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont1=pd.read_csv('/opt/data/netZooPy/regPrior/regMatCont1.csv',header=0,index_col=0)\n",
    "\n",
    "print('the maximum value is ',np.max(cont1.max()))\n",
    "print('the minimum value is ',np.min(cont1.min()))\n",
    "print('Are there null values?', cont1.isnull().values.any())\n",
    "print('The dimensions are:', cont1.shape)\n",
    "print('Matrix density is', np.count_nonzero(cont1)/(cont1.shape[0]*cont1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network includes 1149 TFs and 38723 genes, the largest edge weight is 868.5 and the lowest is 0. The density of the adjaceny matrix is about 91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cont1.values.flatten())\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Edge weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the values are a bit spread, therefore we need to quantile normalize them. Then, we need to scale the values between 0 and 1 to have the same scale of the other input matrices to netZoo tools such as coexpression (between -1 and 1) and PPI matrix (between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantileNormalize(df_input):\n",
    "    df = df_input.copy()\n",
    "    #compute rank\n",
    "    dic = {}\n",
    "    for col in df:\n",
    "        dic.update({col : sorted(df[col])})\n",
    "    sorted_df = pd.DataFrame(dic)\n",
    "    rank = sorted_df.mean(axis = 1).tolist()\n",
    "    #sort\n",
    "    for col in df:\n",
    "        t = np.searchsorted(np.sort(df[col]), df[col])\n",
    "        df[col] = [rank[i] for i in t]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont1qnorm = quantileNormalize(cont1)\n",
    "cont1qnorm = cont1qnorm/(np.max(cont1qnorm.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(cont1qnorm.values.flatten())\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Edge weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Oyuang model\n",
    "We do the same for the second model. Matrix density is identical to the first one, however, the edge weights are more dispersed because we added a significance term to each distance. Edge values are between 0 and 4624 and matrix density is 91% which is equal to the density of the previous model because the only difference was the addition of a significance term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont2=pd.read_csv('/opt/data/netZooPy/regPrior/regMatCont2.csv',header=0,index_col=0)\n",
    "\n",
    "print('the maximum value is ',np.max(cont2.max()))\n",
    "print('the minimum value is ',np.min(cont2.min()))\n",
    "print('Are there null values?', cont2.isnull().values.any())\n",
    "print('The dimensions are:', cont2.shape)\n",
    "print('Matrix density is', np.count_nonzero(cont2)/(cont2.shape[0]*cont2.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cont2.values.flatten());\n",
    "plt.yscale('log', nonposy='clip');\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Edge weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont2qnorm = quantileNormalize(cont2)\n",
    "cont2qnorm = cont2qnorm/(np.max(cont2qnorm.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cont2qnorm.values.flatten());\n",
    "plt.yscale('log', nonpositive='clip');\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Edge weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RP model\n",
    "The RP model edge weight distribution varies between 0 and 7513. The weighted adjacency matrix has the same density than the two other matrices (91%). When we look at the equation of the RP model, we see that when the motif is exactly at the TSS or after the TSS, the distance $d$ to the TSS was set to 0. In the RP model equation, a distance 0 gives an edge weight of 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont3=pd.read_csv('/opt/data/netZooPy/regPrior/regMatCont3.csv',header=0,index_col=0)\n",
    "\n",
    "print('the maximum value is ',np.max(cont3.max()))\n",
    "print('the minimum value is ',np.min(cont3.min()))\n",
    "print('Are there null values?', cont3.isnull().values.any())\n",
    "print('The dimensions are:', cont3.shape)\n",
    "print('Matrix density is', np.count_nonzero(cont3)/(cont3.shape[0]*cont3.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cont3.values.flatten())\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Edge weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont3qnorm = quantileNormalize(cont3)\n",
    "cont3qnorm = cont3qnorm/(np.max(cont3qnorm.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cont3qnorm.values.flatten())\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Edge weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1- Grant, Charles E., Timothy L. Bailey, and William Stafford Noble. \"FIMO: scanning for occurrences of a given motif.\" Bioinformatics 27.7 (2011): 1017-1018.\n",
    "\n",
    "2- Lambert, Samuel A., et al. \"The human transcription factors.\" Cell 172.4 (2018): 650-665.\n",
    "\n",
    "3- Tang, Qianzi, et al. \"A comprehensive view of nuclear receptor cancer cistromes.\" Cancer research 71.22 (2011): 6940-6947.\n",
    "\n",
    "4- Jolma, Arttu, et al. \"DNA-binding specificities of human transcription factors.\" Cell 152.1-2 (2013): 327-339.\n",
    "\n",
    "5- Garcia-Alonso, Luz, et al. \"Benchmark and integration of resources for the estimation of human transcription factor activities.\" Genome research 29.8 (2019): 1363-1375.\n",
    "\n",
    "6- Ouyang, Zhengqing, Qing Zhou, and Wing Hung Wong. \"ChIP-Seq of transcription factors predicts absolute and differential gene expression in embryonic stem cells.\" Proceedings of the National Academy of Sciences 106.51 (2009): 21521-21526.\n",
    "\n",
    "7- Tang, Qianzi, et al. \"A comprehensive view of nuclear receptor cancer cistromes.\" Cancer research 71.22 (2011): 6940-6947.\n",
    "\n",
    "8- Chen, Chen-Hao, et al. \"Determinants of transcription factor regulatory range.\" Nature communications 11.1 (2020): 1-15."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
